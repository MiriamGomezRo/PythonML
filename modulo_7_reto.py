# -*- coding: utf-8 -*-
"""Modulo 7 Reto.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tnPrIQ5V6S12btMMrqoyKDRj_IVFx_Tm

Importar librerias
"""

from sklearn import cluster, metrics
from sklearn.preprocessing import OrdinalEncoder, StandardScaler
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""Leer train.csv"""

df = pd.read_csv("Train.csv")
df

"""Analizar el contenido del dataframe"""

df.dtypes

df.nunique()

df.isna().sum()

"""Imputar valores de dimensiones con valores nulos con la media"""

#Median Age
df['Age'].fillna(df['Age'].median(), inplace=True)
df['Time_of_service'].fillna(df['Time_of_service'].median(), inplace=True)
df['Work_Life_balance'].fillna(df['Work_Life_balance'].median(), inplace=True)
df['Pay_Scale'].fillna(df['Pay_Scale'].median(), inplace=True)
df['VAR2'].fillna(df['VAR2'].median(), inplace=True)
df['VAR4'].fillna(df['VAR4'].median(), inplace=True)

"""Volver a sacar valores nulos"""

df.isna().sum()

"""hacer una copia del Dataframe original"""

df2 = df.copy()

"""Eliminar el campo Employee_ID del dataframe copiado"""

df2= df2.drop(['Employee_ID'], axis=1)
df2

"""Transformar las variables tipo object con ordinal encoding"""

for col in df2.columns:
    if df2[col].dtype == 'object':
        df2[col] = OrdinalEncoder().fit_transform(df2[[col]])
X_train = df2.to_numpy()

"""checar contenido de X_train"""

X_train

"""Construir un array de Subplots para compararlos contra attritin_rate"""

v = 0
fig, axs = plt.subplots(5, 6, figsize=(20, 20))
for i in range(5):
  for j in range(5):
    axs[i,j].scatter(X_train[:,v], X_train[:,22])
    axs[i,j].set_title(df.columns[v])
    axs[i,j].set_ylim([0,0.5e7])
    v+=1
plt.subplots_adjust(hspace=0.5, wspace=0.3)
plt.show()

"""Transformar el contenido de X_train"""

X = StandardScaler().fit_transform(X_train)
X

"""Poner la semilla y numero de centroides"""

nc = 30
np.random.seed(42)

"""Calcular grafica Silhouette"""

results = {}
for k in range(2, nc):
  k_means = cluster.KMeans(n_clusters=k).fit(X)
  y_pred = k_means.predict(X)
  results[k] = metrics.silhouette_score(X, y_pred)

clusters_counts = list(results.keys())
index_values = list(results.values())

plt.plot(clusters_counts, index_values, 'o-')
plt.grid(True)
plt.title('"Maximize"')
plt.xlabel('Num Clusters')
plt.xticks(clusters_counts)
plt.ylabel('Silhouette')
plt.show()

"""k = 4  # Debido principalmente a las gráficas"""

k = 4  # Debido principalmente a las gráficas

k_means = cluster.KMeans(n_clusters=k)
y_pred = k_means.fit_predict(X)

"""Obtener los grupos"""

y_pred

"""Adjuntar columna de Grupos a Dataframe sin nulos"""

df['group'] = y_pred
df

"""obtener centroides"""

k_means.cluster_centers_

"""Hacer un arreglo de dataframes basado en su grupo"""

Employees = []
for g in range(k):
  Employees.append(df[df['group']==g])

for g in range(k):
    print('Group'+str(g),'has',len(Employees[g]),'Employees.')

"""Observar contenido de arreglo de dataframes"""

Employees[0].head()

"""Obtener centroides desde los datos originales divididos por los grupos formados anteriormente"""

grouped = pd.DataFrame()
grouped['Features'] = df.columns[:-1]
for g in range(k):
    row = []
    for col in grouped['Features']:
        if Employees[g][col].dtype != 'object':
            row.append(np.round(Employees[g][col].mean(),2))
        else:
            row.append(Employees[g][col].value_counts().keys()[0])
    grouped['Group'+str(g)] = row
grouped

"""**Conclusiones :**

*El grupo que tiene el mayor indice de resercion en promedio es el Grupo1(.69),
los 4 grupos tienen en comun el genero (F), Estatus de Relacion (Married), ciudad natal(Lebanon), *Unidad (IT), Beneficios y compensaciones (type2)

*El mayor tiempo de servicio se da en el grupo 2 es de 25.8 y el decision_Kill_possess es Directive

*El mayor indice de crecimiento esta en grupo 3 con un tiempo de promedio de 3.47

*La mayor edad promedio registrada es del Grupo 2 y es de 55.01
"""