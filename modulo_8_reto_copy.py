# -*- coding: utf-8 -*-
"""Modulo 8 Reto - Copy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NEQEdCqLXCJ18we556GgNFNSsDT31jrK

**Modulo 8 Reto Employees**
"""

# Commented out IPython magic to ensure Python compatibility.
# importar la biblioteca para análisis de datos
import numpy as np
# importar la biblioteca para graficación
import matplotlib.pyplot as plt
# %matplotlib inline
# importar la biblioteca para manipulación y tratamiento de datos
import pandas as pd

"""Lectura y preprocesamiento del conjunto de datos"""

# leer el conjunto de datos a utilizar
df = pd.read_csv('Employee_Attrition_datos_reto_binario.csv')

# desplegar las primeras 5 líneas del dataframe
df.head()

# mostrar la información condensada del contenido del dataset
df.info()

# determinar la cantidad de datos faltantes en las columnas
df.isnull().sum()

# determinar la cantidad de datos distintos en cada columna
df.nunique()

"""Borrar las siguientes variables por que son irrelevantes para el proposito de Attrition y tienen el mismo valor:  EmployeeCount, EmployeeNumber, Over18, StandardHours"""

df= df.drop(['EmployeeCount', 'EmployeeNumber', 'Over18', 'StandardHours'], axis=1)
df.info()

"""Analizar variables numericas con un boxplot para ver si existen outliers"""

# ilustra los datos de edad con un gráfico de caja - AGE - NO OUTLIERS
df['Age'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - DailyRate - NO OUTLIERS
df['DailyRate'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - DistanceFromHome - NO OUTLIERS
df['DistanceFromHome'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - Education - NO OUTLIERS
df['Education'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - EnvironmentSatisfaction - NO OUTLIERS
df['EnvironmentSatisfaction'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - HourlyRate - NO OUTLIERS
df['HourlyRate'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - JobInvolvement - NO OUTLIERS
df['JobInvolvement'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - JobLevel - NO OUTLIERS
df['JobLevel'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - JobSatisfaction - NO OUTLIERS
df['JobSatisfaction'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - MonthlyIncome - OUTLIERS  usar el RobustScaler escalador
df['MonthlyIncome'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - MonthlyRate -NO OUTLIERS
df['MonthlyRate'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - NumCompaniesWorked - OUTLIERS  usar el RobustScaler escalador
df['NumCompaniesWorked'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - PercentSalaryHike -NO OUTLIERS
df['PercentSalaryHike'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - PerformanceRating  - OUTLIERS  usar el RobustScaler escalador
df['PerformanceRating'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - RelationshipSatisfaction  - No OUTLIERS
df['RelationshipSatisfaction'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - StockOptionLevel  -  OUTLIERS  usar el RobustScaler escalador
df['StockOptionLevel'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - TrainingTimesLastYear  - OUTLIERS  usar el RobustScaler escalador
df['TrainingTimesLastYear'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - WorkLifeBalance   -  No OUTLIERS
df['WorkLifeBalance'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - YearsAtCompany    -  OUTLIERS  usar el RobustScaler escalador
df['YearsAtCompany'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - YearsInCurrentRole    -  OUTLIERS  usar el RobustScaler escalador
df['YearsInCurrentRole'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - YearsInCurrentRole   -  OUTLIERS  usar el RobustScaler escalador
df['YearsSinceLastPromotion'].plot(kind='box')

# ilustra los datos de edad con un gráfico de caja - YearsWithCurrManager   -  OUTLIERS  usar el RobustScaler escalador
df['YearsWithCurrManager'].plot(kind='box')

"""obtener Dummies para los campos Attrition, BusinessTravel, Department, EducationField, Gender, JobRole, MaritalStatus, OverTime,"""

df2 = pd.get_dummies(df,columns=[ 'Attrition', 'BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'OverTime'], drop_first=True)

# muestra las primeras 5 líneas del dataframe resultante
#df2.to_excel('GetDummies.xlsx')
df2.head()
# Y = Attrition_Yes- SALIDA

# Normaliza los datos utilizando el escalador de datos
from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler

dataScaler = RobustScaler()
scaler = dataScaler.fit(df2)
dataScaled = scaler.transform(df2)

# muestra el arreglo resultante
dataScaled

# crea un dataframe con los datos normalizados
data = pd.DataFrame(dataScaled)
data.columns = df2.columns

#data.to_excel('RobustScaled.xlsx')
# muestra las primeras 5 líneas del dataframe resultante
data.head()

data.info()

"""**Creacion de Conjuntos de entrenamiento y prueba**"""

# crea los conjuntos de entrenamiento (80%) y prueba (20%)
from sklearn.model_selection import train_test_split

train_df, test_df = train_test_split(data, test_size=0.2, random_state=123)

# Borrar la columna Attrition_Yes
X_train, y_train = train_df.drop(columns=["Attrition_Yes"], axis=1), train_df["Attrition_Yes"]
X_test, y_test = test_df.drop(columns=["Attrition_Yes"], axis=1), test_df["Attrition_Yes"]

# muestra la forma de los distintos conjuntos de datos obtenidos
print("Datos de entrenamiento=", X_train.shape, y_train.shape)
print("Datos de prueba=", X_test.shape, y_test.shape)

"""**Creacion de Modelos de Aprendizaje**

Bosque Aleatorio
"""

# utiliza validación cruzada de 10 folds para evaluar el desempeño promedio
# de bosques aleatorios de 10 árboles con una profundidad máxima de 3
from sklearn.model_selection import cross_validate
from sklearn.ensemble import RandomForestClassifier

rfcInicial_model = RandomForestClassifier(n_estimators=10, max_depth=3)
scores = pd.DataFrame(cross_validate(rfcInicial_model, X_train, y_train, cv=10, return_train_score=True))

# despliega los score promedio de entrenamiento y validación, así como los
# resultados obtenidos para cada uno de los 10 folds
print("score promedio de entrenamiento = ", scores['train_score'].mean())
print("score promedio de validación = ", scores['test_score'].mean())
scores

# determina, entre algunas alternativas, los mejores valores de hiperparámetros
# para construir un bosque aleatorio para el problema
from sklearn.model_selection import GridSearchCV

parameters = {'max_depth': [2, 3, 5, 7],
              'max_features': ['sqrt', 'log2', None],
              'n_estimators': [10, 30, 60, 100]}
rfc_grid = GridSearchCV(RandomForestClassifier(random_state=1), param_grid = parameters,
                        return_train_score=True)
rfc_grid.fit(X_train, y_train)

# despliega los mejores hiperparámetros encontrados
print("Mejores hiperparámetros\n",rfc_grid.best_params_)

# quédate con el Bosque Aleatorio con los mejores hiperparámetros encontrados y
# despliega su score con los datos del conjunto de prueba.
rfc_model = rfc_grid.best_estimator_
rfc_model.score(X_test, y_test)

# calcula las matriz de confusión y las métricas de evaluación con el conjunto
# de prueba para el mejor Bosque Aleatorio
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import classification_report

ConfusionMatrixDisplay.from_estimator(rfc_model, X_test, y_test)
print(classification_report(y_test, rfc_model.predict(X_test)))

"""**Regresión Logística**"""

# utiliza validación cruzada de 10 folds para evaluar el desempeño promedio
# de una Regresión Logística con C = 0.001 y solver = 'newton-cg'
from sklearn.linear_model import LogisticRegression

lrcInicial_model = LogisticRegression(C=0.001, solver='newton-cg')
scores = pd.DataFrame(cross_validate(lrcInicial_model, X_train, y_train, cv=10, return_train_score=True))

# despliega los score promedio de entrenamiento y validación, así como los
# resultados obtenidos para cada uno de los 10 folds
print("score promedio de entrenamiento = ", scores['train_score'].mean())
print("score promedio de validación = ", scores['test_score'].mean())
scores

# determina, entre algunas alternativas, los mejores valores de hiperparámetros
# para construir un bosque aleatorio para el problema
from sklearn.model_selection import RandomizedSearchCV
import warnings
warnings.filterwarnings("ignore")

parameters = {'C': np.logspace(-4, 4, 50),
              'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}
lrc_rand = RandomizedSearchCV(LogisticRegression(random_state=1), n_iter=48,
                              param_distributions = parameters,
                              return_train_score=True)
lrc_rand.fit(X_train, y_train)

# despliega los mejores hiperparámetros encontrados
print("Mejores hiperparámetros\n", lrc_rand.best_params_)

# quédate con la Regresión Logística con los mejores hiperparámetros encontrados y
# despliega su score con los datos del conjunto de prueba.
lrc_model = lrc_rand.best_estimator_
lrc_model.score(X_test, y_test)

# calcula las matriz de confusión y las métricas de evaluación con el conjunto
# de prueba para la mejor Regresión Logística
ConfusionMatrixDisplay.from_estimator(lrc_model, X_test, y_test)
print(classification_report(y_test, lrc_model.predict(X_test)))

"""**Bayes Ingenuo Gaussiano**"""

# utiliza validación cruzada de 10 folds para evaluar el desempeño promedio
# de Bayes Ingenuo Gaussiano
from sklearn.naive_bayes import GaussianNB

gnbc_model = GaussianNB()

scores = pd.DataFrame(cross_validate(gnbc_model, X_train, y_train, cv=10, return_train_score=True))

# despliega los score promedio de entrenamiento y validación, así como los
# resultados obtenidos para cada uno de los 10 folds
print("score promedio de entrenamiento = ", scores['train_score'].mean())
print("score promedio de validación = ", scores['test_score'].mean())
scores

# calcula las matriz de confusión y métricas de evaluación para el modelo
gnbc_model.fit(X_train, y_train) # No se ha entrenado el modelo

ConfusionMatrixDisplay.from_estimator(gnbc_model, X_test, y_test)
print(classification_report(y_test, gnbc_model.predict(X_test)))

"""**Maquina de Vectores de Soporte**"""

# utiliza validación cruzada de 10 folds para evaluar el desempeño promedio
# de una Máquina de Vectores de Soporte con un parámetro de regularización de
# 0.01 y un kernel polinomial
from sklearn.svm import SVC

svmc_model = SVC(C=0.01, kernel="poly")

scores = pd.DataFrame(cross_validate(svmc_model, X_train, y_train, cv=10, return_train_score=True))

# despliega los score promedio de entrenamiento y validación, así como los
# resultados obtenidos para cada uno de los 10 folds
print("score promedio de entrenamiento = ", scores['train_score'].mean())
print("score promedio de validación = ", scores['test_score'].mean())
scores

# determina, entre algunas alternativas, los mejores valores de hiperparámetros
# para construir una Máquina de Vectores de Soporte para el problema
parameters = {'C': [0.01, 0.1, 1, 10, 50],
              'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}
svmc_grid = GridSearchCV(SVC(random_state=1), param_grid = parameters,
                         return_train_score=True)
svmc_grid.fit(X_train, y_train)
print("Mejores hiperparámetros\n",svmc_grid.best_params_)

# quédate con la Máquina de Vectores de Soporte con los mejores hiperparámetros
# encontrados y despliega su score con los datos del conjunto de prueba.
svmc_model = svmc_grid.best_estimator_
svmc_model.score(X_test, y_test)

# calcula las matriz de confusión y las métricas de evaluación con el conjunto
# de prueba para el mejor Bosque Aleatorio
ConfusionMatrixDisplay.from_estimator(svmc_model, X_test, y_test)
print(classification_report(y_test, svmc_model.predict(X_test)))

"""Mejor Modelo de Aprendizaje mediante Curva ROC"""

# calcular y mostrar las curvas ROC de cada modelo de aprendizaje
# y sus métricas de área bajo la curva (AUC)
from sklearn.metrics import RocCurveDisplay

plt.figure()
lw = 2
disp = RocCurveDisplay.from_estimator(rfc_model, X_test, y_test)
RocCurveDisplay.from_estimator(lrc_model, X_test, y_test, ax=disp.ax_)
RocCurveDisplay.from_estimator(gnbc_model, X_test, y_test, ax=disp.ax_)
RocCurveDisplay.from_estimator(svmc_model, X_test, y_test, ax=disp.ax_)
plt.plot([0, 1], [0, 1], color="navy", lw=lw, linestyle="--")
plt.title("ROC curve comparison")
plt.legend(loc="lower right")
plt.show()

"""Conclusion : Segun los rates de los modelos , con un AUC de .82 los mejores modelos son **Ramdom Forest Classifier y SVC**"""